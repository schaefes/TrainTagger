include:
    - CI/cmssw.yml
    - template: Code-Quality.gitlab-ci.yml

stages:
  - data
  - train
  - evaluate
  - hls4ml
  - synth
  - emulate
  - emulation-evaluate
  - profile
  - upload
  - test

variables:
    Name:  baseline_4_params
    Inputs: baseline
    TRAIN: All200.root
    EOS_DATA_DIR: /eos/cms/store/cmst3/group/l1tr/sewuchte/l1teg/fp_jettuples_090125/
    EOS_STORAGE_DIR: /eos/cms/store/cmst3/group/l1tr/MultiJetTagger
    EOS_STORAGE_SUBDIR: branches/${CI_COMMIT_REF_SLUG}/pipeline${CI_PIPELINE_ID}
    EOS_STORAGE_DATADIR: branches/${CI_COMMIT_REF_SLUG}/${Name}/TrainingFiles
    SCRAM_ARCH: 'el9_amd64_gcc12'
    CMSSW_VERSION: 'CMSSW_14_2_0_pre2'
    CMSSW_L1CT: 'CMS-L1T-Jet-Tagging:14_2_pre2_L1TSC4NGJetTagger'

.template:
  image: gitlab-registry.cern.ch/ml_l1/ops/docker-images/mamba_jettagger:latest
  before_script:
    - export PYTHONPATH=/builds/ml_l1/TrainTagger:$PYTHONPATH
    - echo "$AUTO_DEVOPS_CERNBOX_PASS" | kinit "$AUTO_DEVOPS_CERNBOX_USER@CERN.CH" > /dev/null
  script:
    - python $FOLDER/$SCRIPT $ARGS
  tags:
    - docker
  # rules: # run automatically on default branch, tags, and on merge requests with 'ci::automatic-build' label; otherwise run manually
  #    - if: '($CI_COMMIT_TAG || $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH || $CI_MERGE_REQUEST_LABELS =~ /ci::automatic-build/)'
  #      when: on_success

data:
  extends:
    - .template
  stage: data
  tags: [k8s-gpu]
  variables:
    KUBERNETES_MEMORY_REQUEST: 32Gi
    KUBERNETES_CPU_REQUEST: 2
  rules:
    - changes:  # Include the job and set to when:manual if any of the follow paths match a modified file.
        - tagger/data/**
      when: manual
  script:
  - source activate tagger
  - mkdir data
  - cd data
  - export EOS_MGM_URL=root://eoscms.cern.ch
  - eos cp $EOS_DATA_DIR/${TRAIN} .
  - cd ..
  - python tagger/train/train.py --make-data -i data/${TRAIN} --tree $NTUPLE_TREE -sig $Signal
  - tar -cf training_data_$Inputs.tgz training_data
  - export EOS_MGM_URL=root://eosproject.cern.ch
  - eos mkdir -p ${EOS_STORAGE_DIR}/${EOS_STORAGE_DATADIR}
  - eos cp training_data_$Inputs.tgz ${EOS_STORAGE_DIR}/${EOS_STORAGE_DATADIR}

train:
  extends:
    - .template
  stage: train
  needs:
    - job : data
      optional: true
  script:
  - eos cp ${EOS_STORAGE_DIR}/${EOS_STORAGE_DATADIR}/training_data_$Inputs.tgz .
  - tar -xf training_data_$Inputs.tgz
  - source activate tagger
  - python tagger/train/train.py -n $Name -p 50
  - python tagger/train/train.py --plot-basic -n $Name
  - cd output/baseline
  artifacts:
    paths:
      - output
      - mlflow_run_id.txt
    exclude:
      - .npy
    expire_in: 1 day

evaluate:
  extends:
    - .template
  stage: evaluate
  tags: [k8s-gpu]
  variables:
    KUBERNETES_MEMORY_REQUEST: 32Gi
    KUBERNETES_CPU_REQUEST: 2
  needs: [train]
  script:
  - eos cp ${EOS_STORAGE_DIR}/${EOS_STORAGE_DATADIR}/training_data_$Inputs.tgz .
  - tar -xf training_data_$Inputs.tgz
  - source activate tagger
  - mkdir data
  - cd data
  - eos cp $EOS_DATA_DIR/$MINBIAS .
  - eos cp $BBBB_EOS_DIR/$BBBB .
  - eos cp $BBTT_EOS_DIR/$BBTT .
  - eos cp $EOS_DATA_DIR/$VBFHTAUTAU .
  - cd ..
  - echo "bbbb performance"
  - python tagger/plot/bbbb.py --deriveWPs --minbias data/$MINBIAS -n 650000 --tree $NTUPLE_TREE
  - python tagger/plot/bbbb.py --eff -s data/$BBBB -n 500000 --tree $NTUPLE_TREE
  - echo "bbtt performance"
  - python tagger/plot/bbtt.py --deriveRate --minbias data/$MINBIAS -n 650000 --tree $NTUPLE_TREE
  - python tagger/plot/bbtt.py --deriveWPs --minbias data/$MINBIAS -n 650000 --tree $NTUPLE_TREE
  - python tagger/plot/bbtt.py --eff -s data/$BBTT -n 500000 --tree $NTUPLE_TREE
  - echo "VBF tautau performance"
  - python tagger/plot/diTaus.py --deriveWPs --minbias data/$MINBIAS -n 650000 --tree $NTUPLE_TREE
  - python tagger/plot/diTaus.py --BkgRate --minbias data/$MINBIAS -n 500000 --tree $NTUPLE_TREE
  - python tagger/plot/diTaus.py --eff --vbf_sample data/$VBFHTAUTAU -n 500000 --tree $NTUPLE_TREE
  - echo "Topology tautau performance"
  - python tagger/plot/diTaus_topo.py --deriveWPs --minbias data/$MINBIAS -n 650000 --tree $NTUPLE_TREE
  - python tagger/plot/diTaus_topo.py --BkgRate --minbias data/$MINBIAS -n 500000 --tree $NTUPLE_TREE
  - python tagger/plot/diTaus_topo.py --eff --vbf_sample data/$VBFHTAUTAU -n 500000 --tree $NTUPLE_TREE
  artifacts:
    paths:
      - output
      - mlflow_run_id.txt
    exclude:
      - .npy
    expire_in: 1 day

hls4ml:
  tags: [k8s-gpu]
  variables:
    KUBERNETES_MEMORY_REQUEST: 32Gi
    KUBERNETES_CPU_REQUEST: 4
  extends:
    - .template
  stage: hls4ml
  needs:
    - job : train
  script:
  - source activate tagger
  - python tagger/firmware/hls4ml_convert.py
  artifacts:
    paths:
      - tagger/firmware
    expire_in: 1 day

synth:
  tags:
    - fpga-large
  image: registry.cern.ch/ci4fpga/vivado:2023.2
  stage: synth
  needs : [hls4ml]
  script:
    - cd tagger/firmware/L1TSC4NGJetModel
    - vitis_hls -f build_prj.tcl
    - vivado -mode batch -source vivado_synth.tcl
    - cd ../../..
  artifacts:
    paths:
      - tagger/firmware/L1TSC4NGJetModel
    expire_in: 1 day

emulation-evaluate:
  extends:
    - .template
  stage: emulation-evaluate
  tags: [k8s-gpu]
  variables:
    KUBERNETES_MEMORY_REQUEST: 8Gi
    KUBERNETES_CPU_REQUEST: 2
  needs: [emulate,train,hls4ml]
  dependencies: [emulate,train,hls4ml]
  script:
  - mkdir data
  - cd data
  - cp ../${CMSSW_VERSION}/src/FastPUPPI/NtupleProducer/python/jetTuple_extended_5.root .
  - cd ..
  - source activate tagger
  - python tagger/plot/makeEmulationPlot.py -r True
  artifacts:
    paths:
      - output/baseline
    expire_in: 1 day

profile:
  extends:
    - .template
  stage: profile
  tags: [k8s-gpu]
  variables:
    KUBERNETES_MEMORY_REQUEST: 8Gi
    KUBERNETES_CPU_REQUEST: 2
  needs: [emulate,synth,train]
  dependencies: [emulate,synth,train]
  script:
  - source activate tagger
  - mkdir data
  - cd data
  - cp ../${CMSSW_VERSION}/src/FastPUPPI/NtupleProducer/python/jetTuple_extended_5.root .
  - cd ..
  - pip uninstall hls4ml -y
  - git clone https://github.com/CMS-L1T-Jet-Tagging/hls4ml.git -b jet_tagger
  - cd hls4ml
  - pip install .[profiling]
  - cd ..
  - ls tagger/firmware/L1TSC4NGJetModel/L1TSC4NGJetModel_prj/solution1/syn/report/
  - python tagger/firmware/hls4ml_profile.py -r True -n $Name
  artifacts:
    paths:
      - output/baseline
    expire_in: 1 day

upload:
  image: gitlab-registry.cern.ch/ml_l1/ops/docker-images/mamba_jettagger:latest
  stage: upload
  tags: [k8s-gpu]
  variables:
    KUBERNETES_MEMORY_REQUEST: 4Gi
    KUBERNETES_CPU_REQUEST: 1
  needs: [emulation-evaluate,hls4ml,train,evaluate,profile]
  dependencies: [emulation-evaluate,hls4ml,train,evaluate,profile]
  before_script:
    - export PYTHONPATH=/builds/ml_l1/TrainTagger:$PYTHONPATH
    - echo "$AUTO_DEVOPS_CERNBOX_PASS" | kinit "$AUTO_DEVOPS_CERNBOX_USER@CERN.CH" > /dev/null
  script:
    - source activate tagger
    - mkdir $Name
    - cd tagger/firmware
    - tar -cvf L1TSC4NGJetModel.tgz L1TSC4NGJetModel
    - eos mkdir -p ${EOS_STORAGE_DIR}/${EOS_STORAGE_SUBDIR}/firmware/
    - cp -r L1TSC4NGJetModel.tgz ${EOS_STORAGE_DIR}/${EOS_STORAGE_SUBDIR}/firmware/
    - cd ../..
    - mkdir $Name/plots
    - cp -r output/baseline/model $Name/model
    - mv output/baseline/plots/emulation $Name/plots
    - mv output/baseline/plots/profile $Name/plots
    - mv output/baseline/plots/training/ $Name/plots
    - mv output/baseline/plots/physics/ $Name/plots
    - cd ..
    - rm -rf php-plots
    - git clone https://gitlab-ci-token:${CI_JOB_TOKEN}@gitlab.cern.ch/cms-analysis/general/php-plots.git -b feature/update_extension_grouping
    - export PATH="${PATH}:/builds/ml_l1/php-plots/bin"
    - pb_copy_index.py TrainTagger/${Name} --recursive
    - pb_copy_index.py ${EOS_STORAGE_DIR} --recursive
    - cd TrainTagger/${Name}
    - pb_deploy_plots.py model ${EOS_STORAGE_DIR}/${EOS_STORAGE_SUBDIR} --recursive --extensions h5
    - pb_deploy_plots.py plots ${EOS_STORAGE_DIR}/${EOS_STORAGE_SUBDIR} --recursive --extensions png,pdf
    - cd ..
    - mv CI/mlflow_logger.py .
    - python mlflow_logger.py -w https://cms-l1t-jet-tagger.web.cern.ch/${CI_PROJECT_NAME}/${EOS_STORAGE_SUBDIR}
      -f ${EOS_STORAGE_DIR}/${EOS_STORAGE_SUBDIR}/firmware
      -m ${EOS_STORAGE_DIR}/${EOS_STORAGE_SUBDIR}/model
      -p ${EOS_STORAGE_DIR}/${EOS_STORAGE_SUBDIR}/plots
      -n ${Name}
    - eos rm ${EOS_STORAGE_DIR}/branches/${CI_COMMIT_REF_SLUG}/${Name}/latest || true
    - eos ln ${EOS_STORAGE_DIR}/branches/${CI_COMMIT_REF_SLUG}/${Name}/latest ${EOS_STORAGE_DIR}/${EOS_STORAGE_SUBDIR}
  artifacts:
    paths:
      - $Name
    expire_in: 1 day

code_quality:
   tags:
    - docker-privileged-xl
   artifacts:
    paths: [gl-code-quality-report.json]
